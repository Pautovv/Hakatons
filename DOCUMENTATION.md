## **Задача 1. Система предварительной обработки**

Объясните элементы вашей системы предварительной обработки, т.е. обработку признаков, создание подвыборок, кластеризацию, уменьшение размерности и т. д.
1. Почему вы выбрали эти элементы? (Что-то в разведочном анализе, подсказал предыдущий опыт...?)
1. Как вы оцениваете эффективность этих элементов?
1. Что еще вы пробовали, что сработало или не сработало?


**Ответ участника:**
Сначала мы удаляем ненужный столбец id. Приводим значения в столбцах к целочисленному типу. Выбрали подвыборку MaxPooling, которая является лучшей среди подвыборок по популярности. Кластеризацию мы не использовали.
1. Мы выбрали самые популярные и часто используемые системы предобработки, которые прекрасно справляются с нашими задачами.
2. Мы нормировали данные(привели к виду [0,1], так как таким образом данные имеют меньший разброс и это обеспечивает стабильную сходимость модели. Засчет этого мы увеличили эффективность работы.
3. Мы попробовали использовать StandartScaler и MinMaxScaler, но наша нормировка оказалась лучше.


## **Задание 2. Подход к моделированию**
Объясните свой подход к моделированию, то есть идеи, которые вы пробовали и почему считали их полезными.

1. Как эти решения помогали вам в моделировании?
1. Как вы оцениваете эффективность этих элементов?
1. Что еще вы пробовали, что сработало или не сработало?

**Ответ участника:**
Мы использовали сверточные нейронные сети. Модель состоит из слоев: Conv2D, MaxPooling2D, Dropout и Dense. Мы использовали оптимизатор Adam с параметрами learning_rate = 0.0005, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07 для обучения. С помощью метода to_categorical мы преобразовали векторы классов в матрицы. Мы также использовали call_back.
1. Мы использовали именно эту модель, т к знали, что для подобных задач лучше всего подходит именно она. Мы преобразовывали матрицы в вектор, чтобы работал полносвязный слой Dense. call_back был нужен, чтобы модель не переобучилась
2. Для оценки модели мы использовали метрики 'accuracy' (показывает высокий результат) и 'categorical_crossentropy' в качестве функции потерь.    
3. Мы пробовали разные гиперпараметры в процессе обучение, изменяли кол-во слоёв и их параметры, пытались также не допускать переобучение.

# **Ссылки на использованные источники:**

*   https://ru-keras.com
*   https://habr.com
*   https://education.yandex.ru/handbook/ml
*   https://www.kaggle.com/learn/intro-to-deep-learning
*   https://www.youtube.com/@machine_learrrning
*   https://stepik.org/course/181974/syllabus
*   https://stackoverflow.com/
*   https://github.com/
